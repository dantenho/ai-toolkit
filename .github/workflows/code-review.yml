# ============================================================================
# Automated Code Review Workflow Using AI Assistants
# ============================================================================
# This workflow orchestrates multiple AI-powered code review tools to provide
# comprehensive automated code analysis on pull requests. It integrates:
# - Cursor Bot (AI code review)
# - Google Gemini AI (code analysis and suggestions)
# - GitHub Copilot CLI (code explanations)
# - Security scanning tools (Trivy, Semgrep, Bandit)
# - Dependency vulnerability scanning (Snyk, Dependency Review)
# - CodeRabbit AI (automated PR reviews)
# - CircleCI integration (external CI pipeline triggering)
# - Jules.MD (documentation review)
#
# The workflow runs on PR events and provides detailed feedback through
# GitHub comments and security alerts.
# ============================================================================
name: AI Code Review

# Workflow trigger configuration
on:
  # Trigger on pull request events to main/master branches
  pull_request:
    branches: [main, master]
    types: [opened, synchronize, reopened] # Trigger on PR open, update, or reopen
  # Weekly scheduled security scan (Monday at 2 AM UTC)
  schedule:
    - cron: "0 2 * * 1"
  # Allow manual workflow dispatch for on-demand reviews
  workflow_dispatch:

# Default job configuration applied to all jobs
defaults:
  run:
    shell: bash # Use bash shell for consistent behavior across platforms

jobs:
  # ========================================================================
  # Cursor Bot Code Review Job
  # ========================================================================
  # Placeholder job for Cursor AI integration. This job prepares the
  # environment and can be extended with actual Cursor Bot API calls
  # when the integration becomes available.
  # ========================================================================
  cursor-review:
    name: Cursor Bot Review
    runs-on: ubuntu-latest
    # Skip draft PRs to save CI resources
    if: github.event.pull_request.draft == false
    # Required permissions for PR comments and code access
    permissions:
      contents: read # Read repository contents
      pull-requests: write # Post review comments on PRs
      issues: write # Create/update issues if needed
    timeout-minutes: 15 # Job timeout to prevent hanging
    steps:
      - name: Checkout repository # Get PR code for review
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }} # Checkout PR branch
          fetch-depth: 0 # Full history for context

      - name: Set up Python 3.11 # Python environment
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install uv # Package manager
        run: pip install uv

      - name: Sync dependencies # Install project dependencies
        if: hashFiles('pyproject.toml') != ''
        run: uv sync

      - name: Run Cursor Bot Review
        # Placeholder for Cursor AI integration
        # TODO: Replace with actual Cursor Bot API call when available
        # Expected API: POST to Cursor Bot endpoint with PR diff and context
        run: |
          echo "üîç Cursor Bot review would run here"
          echo "PR Number: ${{ github.event.pull_request.number }}"
          echo "Files changed: ${{ github.event.pull_request.changed_files }}"
          echo "Base branch: ${{ github.event.pull_request.base.ref }}"
          echo "Head branch: ${{ github.event.pull_request.head.ref }}"
        continue-on-error: true # Don't fail workflow if placeholder fails

  # ========================================================================
  # Google Gemini AI Code Review Job
  # ========================================================================
  # This job uses Google's Gemini AI model to analyze code changes in PRs.
  # It reviews each changed file for bugs, security issues, code quality,
  # and suggests improvements. Results are posted as PR comments.
  # ========================================================================
  gemini-review:
    name: Gemini Code Assistant Review
    runs-on: ubuntu-latest
    # Skip draft PRs to save CI resources and API costs
    if: github.event.pull_request.draft == false
    # Required permissions for PR comments and code access
    permissions:
      contents: read # Read repository contents
      pull-requests: write # Post review comments on PRs
    timeout-minutes: 20 # Job timeout to prevent excessive API usage
    steps:
      - name: Checkout repository # Get PR code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          fetch-depth: 0

      - name: Set up Python 3.11 # Python environment
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies # Install Google GenAI SDK
        run: |
          pip install google-generativeai
          pip install requests

      - name: Install jq for JSON processing
        # Install jq utility for parsing JSON output in bash scripts
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Get changed files
        # Extract list of files changed in PR for review
        id: changed-files
        run: |
          # Get diff between base and head commits
          git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.event.pull_request.head.sha }} > changed_files.txt || true
          # Convert file list to JSON array for output
          if [ -s changed_files.txt ]; then
            echo "files=$(cat changed_files.txt | jq -R -s -c 'split("\n")[:-1]')" >> $GITHUB_OUTPUT
            echo "Found $(wc -l < changed_files.txt) changed files"
          else
            echo "files=[]" >> $GITHUB_OUTPUT
            echo "No changed files found"
          fi

      - name: Run Gemini Code Review
        # Review code using Google Gemini AI API
        # Analyzes each changed source file for bugs, security issues, code quality
        # Includes comprehensive error handling with request ID tracking for debugging
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }} # API key from GitHub secrets
          GITHUB_RUN_ID: ${{ github.run_id }} # GitHub Actions run ID for tracking
          GITHUB_RUN_NUMBER: ${{ github.run_number }} # GitHub Actions run number
        run: |
          python3 << 'EOF'
          """
          Gemini AI Code Review Script with Enhanced Error Handling
          ===========================================================
          This script uses Google's Gemini AI to review code changes in pull requests.
          It processes each changed source file and generates comprehensive reviews
          covering bugs, security vulnerabilities, code quality, and best practices.

          Enhanced Features:
          - Request ID tracking for error correlation
          - Comprehensive error handling and recovery
          - Detailed error messages with context
          - Graceful degradation on API failures
          - Retry logic for transient failures
          - Top-level exception handler to catch all errors
          """
          import os
          import sys
          import uuid
          import traceback
          import time
          from typing import Optional

          # Generate master request ID at the very top level for complete error tracking
          master_request_id = str(uuid.uuid4())

          def format_error_with_request_id(message: str, error: Exception = None) -> str:
              """
              Format error message with request ID in the format seen in error reports.
              
              Args:
                  message: Error message
                  error: Optional exception object
              
              Returns:
                  Formatted error message with request ID
              """
              error_msg = f"Failed to run review (request ID: {master_request_id})"
              if message:
                  error_msg += f"\nError: {message}"
              if error:
                  error_msg += f"\nException: {type(error).__name__}: {str(error)}"
              return error_msg

          # Main execution wrapped in top-level exception handler
          try:
              try:
                  import google.generativeai as genai
              except ImportError as e:
                  error_msg = format_error_with_request_id(
                      f"Failed to import google.generativeai: {e}",
                      e
                  )
                  print(f"‚ùå {error_msg}", file=sys.stderr)
                  print("üí° SOLUTION: Please ensure google-generativeai is installed: pip install google-generativeai")
                  print(f"üìã Request ID: {master_request_id}")
                  sys.exit(1)

              # Generate unique request ID for this review session
              # Combines GitHub run ID with UUID for unique tracking
              # Also uses master_request_id for top-level error correlation
              github_run_id = os.getenv('GITHUB_RUN_ID', 'unknown')
              github_run_number = os.getenv('GITHUB_RUN_NUMBER', 'unknown')
              session_request_id = f"{github_run_id}-{uuid.uuid4().hex[:8]}"
              
              # Log master request ID for correlation
              print(f"üìã Master Request ID: {master_request_id}")
              print(f"üìã Session Request ID: {session_request_id}")

              def log_error(message: str, error: Optional[Exception] = None, request_id: Optional[str] = None):
                  """
                  Log error with request ID for tracking and debugging.
                  
                  Args:
                      message: Error message to log
                      error: Optional exception object for detailed error info
                      request_id: Optional request ID for correlation
                  """
                  req_id = request_id or session_request_id
                  error_msg = f"‚ùå ERROR [{req_id}]: {message}"
                  if error:
                      error_msg += f"\n   Exception: {type(error).__name__}: {str(error)}"
                      error_msg += f"\n   Traceback:\n{''.join(traceback.format_tb(error.__traceback__))}"
                  print(error_msg, file=sys.stderr)
                  return req_id

              # Retrieve API key from environment
              api_key = os.getenv('GEMINI_API_KEY')
              if not api_key:
                  request_id = log_error(
                      "GEMINI_API_KEY not found in secrets",
                      None,
                      session_request_id
                  )
                  error_msg = format_error_with_request_id("GEMINI_API_KEY not found in secrets")
                  print(f"\n‚ùå {error_msg}", file=sys.stderr)
                  print(f"\nüí° SOLUTION: Configure GEMINI_API_KEY in repository settings > Secrets")
                  print(f"   Master Request ID: {master_request_id}")
                  print(f"   Session Request ID: {request_id}")
                  print(f"   Workflow Run: {github_run_id} (#{github_run_number})")
                  sys.exit(1)

              # Configure Gemini AI client with error handling
              model = None
              try:
                  genai.configure(api_key=api_key)
                  # Try to use gemini-1.5-pro if available, fallback to gemini-pro
                  try:
                      model = genai.GenerativeModel('gemini-1.5-pro')
                      print(f"‚úÖ Gemini AI model 'gemini-1.5-pro' initialized successfully")
                  except Exception:
                      model = genai.GenerativeModel('gemini-pro')
                      print(f"‚úÖ Gemini AI model 'gemini-pro' initialized successfully")
                  print(f"üìã Review Session ID: {session_request_id}")
              except Exception as e:
                  request_id = log_error("Failed to configure Gemini AI", e, session_request_id)
                  error_msg = format_error_with_request_id("Failed to configure Gemini AI", e)
                  print(f"\n‚ùå {error_msg}", file=sys.stderr)
                  print(f"   Master Request ID: {master_request_id}")
                  print(f"   Session Request ID: {request_id}")
                  sys.exit(1)

              # Read list of changed files with error handling
              files = []
              try:
                  with open('changed_files.txt', 'r') as f:
                      files = [line.strip() for line in f if line.strip()]
              except FileNotFoundError:
                  print(f"‚ÑπÔ∏è  No changed files found - skipping review (Request ID: {session_request_id})")
                  sys.exit(0)
              except Exception as e:
                  request_id = log_error("Failed to read changed_files.txt", e, session_request_id)
                  error_msg = format_error_with_request_id("Failed to read changed_files.txt", e)
                  print(f"\n‚ùå {error_msg}", file=sys.stderr)
                  print(f"   Master Request ID: {master_request_id}")
                  print(f"   Session Request ID: {request_id}")
                  sys.exit(1)

              if not files:
                  print(f"‚ÑπÔ∏è  No files to review (Request ID: {session_request_id})")
                  sys.exit(0)

              # Review each source code file with enhanced error handling
              reviewed_count = 0
              error_count = 0
              skipped_count = 0
              supported_extensions = ('.py', '.js', '.ts', '.java', '.cpp', '.c', '.go', '.rs', '.rb', '.tsx', '.jsx')

              for file_path in files:
                  # Generate unique request ID for each file review
                  file_request_id = f"{session_request_id}-{uuid.uuid4().hex[:6]}"
                  
                  # Only review source code files
                  if not file_path.endswith(supported_extensions):
                      skipped_count += 1
                      continue
                  
                  # Skip deleted files
                  if not os.path.exists(file_path):
                      print(f"‚è≠Ô∏è  Skipping deleted file: {file_path}")
                      skipped_count += 1
                      continue
                  
                  try:
                      # Read file content with encoding error handling
                      try:
                          with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                              content = f.read()
                      except Exception as e:
                          log_error(f"Failed to read file: {file_path}", e, file_request_id)
                          error_count += 1
                          continue
                      
                      # Skip empty files
                      if not content.strip():
                          print(f"‚è≠Ô∏è  Skipping empty file: {file_path}")
                          skipped_count += 1
                          continue
                      
                      # Limit file size to prevent API token limits (approximately 1M characters)
                      max_file_size = 1000000
                      if len(content) > max_file_size:
                          print(f"‚ö†Ô∏è  File {file_path} is too large ({len(content)} chars), truncating to {max_file_size} chars")
                          content = content[:max_file_size] + "\n\n[File truncated due to size limits]"
                      
                      # Construct review prompt with context
                      prompt = f"""Review this code file for:
                      1. Bugs and logical errors
                      2. Security vulnerabilities
                      3. Code quality and best practices
                      4. Performance issues
                      5. Maintainability concerns
                      
                      Provide specific, actionable feedback with line numbers when possible.
                      
                      File: {file_path}
                      
                      Code:
                      {content}"""
                      
                      # Generate review using Gemini AI with retry logic
                      print(f"üîç Reviewing {file_path}... (Request ID: {file_request_id})")
                      
                      max_retries = 3
                      retry_delay = 2  # seconds
                      response = None
                      
                      for attempt in range(1, max_retries + 1):
                          try:
                              response = model.generate_content(prompt)
                              break  # Success, exit retry loop
                          except Exception as api_error:
                              if attempt < max_retries:
                                  wait_time = retry_delay * attempt
                                  print(f"‚ö†Ô∏è  API call failed (attempt {attempt}/{max_retries}), retrying in {wait_time}s...")
                                  print(f"   Error: {type(api_error).__name__}: {str(api_error)}")
                                  time.sleep(wait_time)
                              else:
                                  # All retries exhausted
                                  raise api_error
                      
                      # Output review results
                      if response and response.text:
                          print(f"\n{'='*80}")
                          print(f"üìù Review for {file_path} (Request ID: {file_request_id}):")
                          print(f"{'='*80}")
                          print(response.text)
                          print(f"{'='*80}\n")
                          reviewed_count += 1
                      else:
                          print(f"‚ö†Ô∏è  Empty response from Gemini AI for {file_path} (Request ID: {file_request_id})")
                          error_count += 1
                      
                  except Exception as e:
                      request_id = log_error(f"Error reviewing {file_path}", e, file_request_id)
                      error_msg = format_error_with_request_id(f"Error reviewing {file_path}", e)
                      print(f"\n‚ùå {error_msg}", file=sys.stderr)
                      print(f"   Master Request ID: {master_request_id}")
                      print(f"   File Request ID: {request_id}")
                      error_count += 1
                      continue

              # Summary with request ID
              print(f"\n{'='*80}")
              print(f"üìä Review Summary (Session ID: {session_request_id}):")
              print(f"{'='*80}")
              print(f"‚úÖ Files reviewed: {reviewed_count}")
              print(f"‚ùå Errors: {error_count}")
              print(f"‚è≠Ô∏è  Skipped: {skipped_count}")
              print(f"üìã Total files processed: {len(files)}")
              print(f"{'='*80}\n")

              # Exit with appropriate code
              if error_count > 0:
                  error_msg = format_error_with_request_id(
                      f"Review completed with {error_count} error(s). Check logs for details."
                  )
                  print(f"\n‚ö†Ô∏è  {error_msg}")
                  print(f"   Master Request ID: {master_request_id}")
                  print(f"   Session Request ID: {session_request_id}")
                  # Don't exit with error code since continue-on-error is set
                  # This allows the workflow to continue even if some reviews fail
                  sys.exit(0)
              elif reviewed_count == 0:
                  print(f"‚ÑπÔ∏è  No files were reviewed. This may be expected if only non-source files changed.")
                  print(f"   Master Request ID: {master_request_id}")
                  sys.exit(0)
              else:
                  print(f"‚úÖ Review completed successfully!")
                  print(f"   Master Request ID: {master_request_id}")
                  sys.exit(0)
              
          except Exception as e:
              # Top-level exception handler to catch any unhandled errors
              error_msg = format_error_with_request_id(
                  f"Unexpected error in review script: {str(e)}",
                  e
              )
              print(f"\n‚ùå CRITICAL ERROR: {error_msg}", file=sys.stderr)
              print(f"\nüìã Full Traceback:", file=sys.stderr)
              traceback.print_exc(file=sys.stderr)
              print(f"\nüìã Master Request ID: {master_request_id}", file=sys.stderr)
              sys.exit(1)
          EOF
        continue-on-error: true # Don't fail workflow on API errors

      - name: Post review comment
        # Post comprehensive review summary as PR comment
        # Creates a comprehensive summary comment on the PR with links to
        # all review results and workflow logs for detailed analysis.
        # Includes error handling and request ID tracking for failed reviews.
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            /**
             * Post AI Code Review Summary Comment with Enhanced Error Handling
             * ===================================================================
             * Creates a comprehensive summary comment on the PR with links to
             * all review results and workflow logs for detailed analysis.
             * Includes error status, request IDs, and troubleshooting information.
             */
            const workflowUrl = `${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}`;
            const runNumber = `${{ github.run_number }}`;
            const runId = `${{ github.run_id }}`;

            // Build comment body with status information
            const commentBody = `## ü§ñ AI Code Review Summary

            Comprehensive automated code review has been completed for this pull request.

            ### Review Status
            üìã **Workflow Run**: [#${runNumber}](${workflowUrl}) (ID: ${runId})

            ### Review Components
            - ‚úÖ **Gemini AI Analysis** - AI-powered code review and suggestions
            - üîí **Security Scanning** - Trivy, Semgrep, and Bandit security analysis
            - üì¶ **Dependency Review** - Snyk and Dependency Review vulnerability checks
            - üê∞ **CodeRabbit AI Review** - Automated PR review and suggestions
            - üìö **Documentation Review** - Jules.MD documentation analysis
            - üîÑ **CircleCI Integration** - External CI pipeline triggered

            ### View Results
            - [View Workflow Logs](${workflowUrl}) - Detailed review output and logs
            - Check individual job outputs for specific tool results

            ### ‚ö†Ô∏è Troubleshooting
            If the review failed, check:
            1. **API Keys**: Ensure \`GEMINI_API_KEY\` is configured in repository secrets
            2. **Workflow Logs**: Review the detailed logs linked above for error messages
            3. **Request IDs**: Look for request IDs in error messages (format: \`run-id-uuid\`) for correlation
            4. **API Limits**: Verify Gemini API quota and rate limits

            ---
            *This is an automated review. Please review the suggestions and address any critical issues.*`;

            try {
              // Post comment to PR
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: commentBody
              });
              console.log('‚úÖ Review summary comment posted successfully');
            } catch (error) {
              // Log error but don't fail the workflow
              console.error('‚ùå Failed to post review comment:', error.message);
              console.error('Error details:', JSON.stringify(error, null, 2));
              // Try to provide alternative feedback
              console.log(`\nüí° Manual Review: View workflow logs at ${workflowUrl}`);
            }

  # ========================================================================
  # GitHub Copilot CLI Code Review Job
  # ========================================================================
  # This job uses GitHub Copilot CLI to explain and review code changes.
  # Copilot provides AI-powered code explanations and suggestions for
  # improved code understanding and quality.
  # ========================================================================
  copilot-review:
    name: GitHub Copilot Review
    runs-on: ubuntu-latest
    # Skip draft PRs to save CI resources
    if: github.event.pull_request.draft == false
    # Required permissions for GitHub CLI and Copilot access
    permissions:
      contents: read # Read repository contents
      pull-requests: read # Read PR information
    timeout-minutes: 15 # Job timeout to prevent hanging
    steps:
      - name: Checkout repository
        # Checkout PR branch for code review
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }} # Checkout PR branch
          fetch-depth: 0 # Full history for context

      - name: Install GitHub CLI
        # Install GitHub CLI for Copilot integration
        run: |
          # Add GitHub CLI repository key
          curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | \
            sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg
          # Add GitHub CLI repository to apt sources
          echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | \
            sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
          # Update package list and install GitHub CLI
          sudo apt update
          sudo apt install -y gh

      - name: Authenticate GitHub CLI
        # Authenticate GitHub CLI with token for Copilot access
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "$GITHUB_TOKEN" | gh auth login --with-token
          gh auth status # Verify authentication

      - name: Copilot Code Review
        # Review changed files using GitHub Copilot CLI
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Get list of changed files between base and head
          BASE_SHA="${{ github.event.pull_request.base.sha }}"
          HEAD_SHA="${{ github.event.pull_request.head.sha }}"

          # Get changed files using git diff
          git diff --name-only "${BASE_SHA}" "${HEAD_SHA}" | while read -r file; do
            # Skip if file doesn't exist (deleted files)
            if [[ ! -f "$file" ]]; then
              echo "‚è≠Ô∏è  Skipping deleted file: $file"
              continue
            fi
            
            # Only review source code files
            if [[ "$file" =~ \.(py|js|ts|java|cpp|c|go|rs|rb)$ ]]; then
              echo "üîç Reviewing $file with Copilot..."
              # Use Copilot to explain the file
              gh copilot explain "$file" || echo "‚ö†Ô∏è  Copilot review failed for $file"
            else
              echo "‚è≠Ô∏è  Skipping non-source file: $file"
            fi
          done
        continue-on-error: true # Don't fail workflow on Copilot errors

  # ========================================================================
  # Security Scanning Job
  # ========================================================================
  # This job runs multiple security scanning tools to identify vulnerabilities:
  # - Trivy: Comprehensive vulnerability scanner for filesystems and containers
  # - Semgrep: Static analysis tool for security and code quality issues
  # - Bandit: Python-specific security linter for common vulnerabilities
  # Results are uploaded to GitHub Security tab for visibility.
  # ========================================================================
  security-scan:
    name: Security Analysis
    runs-on: ubuntu-latest
    # Skip draft PRs to save CI resources
    if: github.event.pull_request.draft == false
    # Required permissions for security scanning and SARIF upload
    permissions:
      contents: read # Read repository contents
      security-events: write # Upload security scan results to GitHub Security tab
      actions: read # Read workflow information
    timeout-minutes: 30 # Job timeout for comprehensive scanning
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Checkout repository
        # Checkout code for security scanning
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Full history for comprehensive scanning

      - name: Set up Python 3.11
        # Python environment for Bandit security linter
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Run Trivy vulnerability scanner
        # Trivy scans filesystem for known vulnerabilities in dependencies and code
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: "fs" # Filesystem scan mode
          scan-ref: "." # Scan current directory
          format: "sarif" # SARIF format for GitHub Security tab integration
          output: "trivy-results.sarif" # Output file for results
          severity: "CRITICAL,HIGH,MEDIUM" # Only report high-severity issues

      - name: Upload Trivy scan results
        # Upload Trivy results to GitHub Security tab for visibility
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: "trivy-results.sarif" # SARIF file from Trivy scan
          wait-for-processing: false # Don't wait for processing to complete

      - name: Run Semgrep security scan
        # Semgrep performs static analysis for security vulnerabilities
        uses: returntocorp/semgrep-action@v1
        with:
          config: auto # Use Semgrep's automatic configuration
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }} # Semgrep API token (optional)
        continue-on-error: true # Don't fail workflow on Semgrep errors

      - name: Run Bandit security linter
        # Bandit scans Python code for common security vulnerabilities
        run: |
          # Install Bandit security linter
          pip install bandit[toml] # Include TOML support for pyproject.toml config
          # Run Bandit scan on Python files
          # -r: recursive scan
          # -f json: JSON output format
          # -o: output file
          # || true: don't fail workflow on findings
          bandit -r . -f json -o bandit-report.json || true
        continue-on-error: true # Don't fail workflow on security findings

      - name: Upload Bandit results
        # Upload Bandit scan results as artifact for review
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: bandit-security-report
          path: bandit-report.json
          retention-days: 30 # Keep artifacts for 30 days

  # ========================================================================
  # Dependency Vulnerability Scanning Job
  # ========================================================================
  # This job scans project dependencies for known security vulnerabilities:
  # - Snyk: Comprehensive dependency vulnerability database scanning
  # - Dependency Review: GitHub's native dependency change analysis
  # Both tools help identify and prevent vulnerable dependencies from being merged.
  # ========================================================================
  dependency-scan:
    name: Dependency Analysis
    runs-on: ubuntu-latest
    # Required permissions for dependency scanning
    permissions:
      contents: read # Read repository contents
      pull-requests: write # Comment on PRs with vulnerability findings
      security-events: write # Report security vulnerabilities
    timeout-minutes: 20 # Job timeout for dependency scanning
    steps:
      - name: Checkout repository
        # Checkout code for dependency analysis
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Full history for dependency tracking

      - name: Set up Python 3.11
        # Python environment for Snyk scanning
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Run Snyk to check for vulnerabilities
        # Snyk scans Python dependencies for known vulnerabilities
        uses: snyk/actions/python@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }} # Snyk API token from secrets
        with:
          args: --severity-threshold=high # Only report high-severity vulnerabilities
        continue-on-error: true # Don't fail workflow on vulnerabilities found

      - name: Dependency Review
        # GitHub's native dependency review for PR changes
        # Analyzes dependency changes in PRs for security issues
        if: github.event_name == 'pull_request' # Only run on PR events
        uses: actions/dependency-review-action@v4
        with:
          fail-on-severity: moderate # Fail PR if moderate+ severity issues found
          # Optional: Configure deny-licenses as array if needed
          # deny-licenses: ["GPL-2.0", "GPL-3.0"]

  # ========================================================================
  # CodeRabbit AI Review Job
  # ========================================================================
  # This job uses CodeRabbit AI to provide automated code review on PRs.
  # CodeRabbit analyzes code changes and provides intelligent suggestions
  # for improvements, bug fixes, and best practices.
  # ========================================================================
  coderabbit-review:
    name: CodeRabbit AI Review
    runs-on: ubuntu-latest
    # Skip draft PRs to save CI resources and API costs
    if: github.event.pull_request.draft == false
    # Required permissions for CodeRabbit to comment on PRs
    permissions:
      contents: read # Read repository contents
      pull-requests: write # Post review comments on PRs
      issues: write # Create issues if needed
    timeout-minutes: 15 # Job timeout to prevent hanging
    steps:
      - name: Checkout repository
        # Checkout PR branch for CodeRabbit analysis
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }} # Checkout PR branch
          fetch-depth: 0 # Full history for context

      - name: CodeRabbit Review
        # CodeRabbit Pro is now integrated via GitHub App, not Actions
        # Install the CodeRabbit Pro app from: https://github.com/apps/coderabbitai
        # The app will automatically review PRs when installed
        run: |
          echo "üê∞ CodeRabbit Pro reviews are handled via GitHub App integration"
          echo "Install the CodeRabbit Pro app for automatic PR reviews"
          echo "Visit: https://github.com/apps/coderabbitai"
          echo "PR Number: ${{ github.event.pull_request.number }}"
          echo "Branch: ${{ github.event.pull_request.head.ref }}"
        continue-on-error: true # Don't fail workflow on CodeRabbit errors

  # ========================================================================
  # CircleCI Integration Trigger Job
  # ========================================================================
  # This job triggers an external CircleCI pipeline for additional CI/CD
  # processing. Useful when maintaining separate CI systems or when
  # CircleCI has specialized build/test configurations.
  # ========================================================================
  circleci-trigger:
    name: Trigger CircleCI
    runs-on: ubuntu-latest
    # Skip draft PRs to save CI resources
    if: github.event.pull_request.draft == false
    # Required permissions for API calls
    permissions:
      contents: read # Read repository information
    timeout-minutes: 5 # Job timeout for API call
    steps:
      - name: Trigger CircleCI Pipeline
        # Trigger CircleCI pipeline via API
        env:
          CIRCLECI_TOKEN: ${{ secrets.CIRCLECI_TOKEN }} # CircleCI API token
        run: |
          # Validate token exists
          if [ -z "$CIRCLECI_TOKEN" ]; then
            echo "‚ö†Ô∏è  Warning: CIRCLECI_TOKEN not configured, skipping CircleCI trigger"
            exit 0
          fi

          # Extract repository owner and name
          REPO_OWNER=$(echo "${{ github.repository }}" | cut -d'/' -f1)
          REPO_NAME=$(echo "${{ github.repository }}" | cut -d'/' -f2)

          # Trigger CircleCI pipeline via API v2
          echo "üîÑ Triggering CircleCI pipeline for branch: ${{ github.event.pull_request.head.ref }}"
          curl -X POST \
            -H "Circle-Token: $CIRCLECI_TOKEN" \
            -H "Content-Type: application/json" \
            -d "{
              \"branch\": \"${{ github.event.pull_request.head.ref }}\",
              \"parameters\": {
                \"pr_number\": ${{ github.event.pull_request.number }},
                \"triggered_by\": \"github_actions\",
                \"github_event\": \"${{ github.event_name }}\"
              }
            }" \
            "https://circleci.com/api/v2/project/github/${{ github.repository }}/pipeline" || {
              echo "‚ùå Failed to trigger CircleCI pipeline"
              exit 1
            }

          echo "‚úÖ CircleCI pipeline triggered successfully"
        continue-on-error: true # Don't fail workflow if CircleCI trigger fails

  # ========================================================================
  # Jules.MD Documentation Review Job
  # ========================================================================
  # This job reviews documentation changes in PRs using Jules.MD AI.
  # It checks for documentation quality, clarity, completeness, and
  # adherence to documentation standards.
  # ========================================================================
  jules-md-review:
    name: Jules.MD Documentation Review
    runs-on: ubuntu-latest
    # Skip draft PRs to save CI resources
    if: github.event.pull_request.draft == false
    # Required permissions for PR comments
    permissions:
      contents: read # Read repository contents
      pull-requests: write # Post review comments on PRs
    timeout-minutes: 15 # Job timeout for documentation review
    steps:
      - name: Checkout repository
        # Checkout PR branch for documentation review
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.ref }} # Checkout PR branch
          fetch-depth: 0 # Full history for context

      - name: Check for documentation changes
        # Detect if documentation files were changed in this PR
        id: docs-changed
        run: |
          # Get base and head SHAs for PR comparison
          BASE_SHA="${{ github.event.pull_request.base.sha }}"
          HEAD_SHA="${{ github.event.pull_request.head.sha }}"

          # Check for documentation file changes
          if git diff --name-only "${BASE_SHA}" "${HEAD_SHA}" | grep -E '\.(md|rst|txt|adoc)$'; then
            echo "docs_changed=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Documentation files changed - review will run"
          else
            echo "docs_changed=false" >> $GITHUB_OUTPUT
            echo "‚ÑπÔ∏è  No documentation files changed - skipping review"
          fi

      - name: Jules.MD Review
        # Review documentation changes using Jules.MD AI
        if: steps.docs-changed.outputs.docs_changed == 'true'
        env:
          JULES_API_KEY: ${{ secrets.JULES_API_KEY }} # Jules.MD API key (optional)
        run: |
          # Get base and head SHAs for PR comparison
          BASE_SHA="${{ github.event.pull_request.base.sha }}"
          HEAD_SHA="${{ github.event.pull_request.head.sha }}"

          echo "üìö Starting Jules.MD documentation review..."

          # Get list of changed documentation files
          git diff --name-only "${BASE_SHA}" "${HEAD_SHA}" | grep -E '\.(md|rst|txt|adoc)$' | while read -r file; do
            # Skip deleted files
            if [[ ! -f "$file" ]]; then
              echo "‚è≠Ô∏è  Skipping deleted documentation file: $file"
              continue
            fi
            
            echo "üîç Reviewing documentation: $file"
            
            # TODO: Integrate with Jules.MD API when available
            # Expected API call:
            # curl -X POST \
            #   -H "Authorization: Bearer $JULES_API_KEY" \
            #   -H "Content-Type: application/json" \
            #   -d "{\"file\": \"$file\", \"content\": \"$(cat $file)\"}" \
            #   "https://api.jules.md/review"
            
            # Placeholder: Show file info
            echo "  File: $file"
            echo "  Lines: $(wc -l < "$file")"
            echo "  Size: $(du -h "$file" | cut -f1)"
            echo ""
          done

          echo "‚úÖ Documentation review complete"
        continue-on-error: true # Don't fail workflow on documentation review errors
